{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TP_segmentation_Pytorch.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab_type":"code","id":"W7QSW23GYZam","colab":{"base_uri":"https://localhost:8080/","height":239},"outputId":"d1a1ada5-ec2e-471c-855e-5e6bea285ed5","executionInfo":{"status":"ok","timestamp":1581677643807,"user_tz":-60,"elapsed":159229,"user":{"displayName":"Maria Vakalopoulou","photoUrl":"","userId":"15219843109081260770"}}},"source":["!pip install SimpleITK\n","!git clone https://github.com/EPU-IA-2020/TP3.git\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting SimpleITK\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/d8/53338c34f71020725ffb3557846c80af96c29c03bc883551a2565aa68a7c/SimpleITK-1.2.4-cp36-cp36m-manylinux1_x86_64.whl (42.5MB)\n","\u001b[K     |████████████████████████████████| 42.5MB 72kB/s \n","\u001b[?25hInstalling collected packages: SimpleITK\n","Successfully installed SimpleITK-1.2.4\n","Cloning into 'TP3'...\n","remote: Enumerating objects: 105090, done.\u001b[K\n","remote: Total 105090 (delta 0), reused 0 (delta 0), pack-reused 105090\u001b[K\n","Receiving objects: 100% (105090/105090), 1.77 GiB | 16.71 MiB/s, done.\n","Resolving deltas: 100% (29/29), done.\n","Checking out files: 100% (130744/130744), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"13YDHJHyC8td","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","import torch.utils.data\n","import torch.utils.tensorboard\n","import torchvision\n","import torchvision.transforms\n","import os\n","import time\n","import numpy as np\n","import skimage.transform\n","import matplotlib.pyplot as plt\n","import SimpleITK as sitk\n","import pandas as pd\n","import sklearn.model_selection as model_selection\n","from tqdm import tqdm"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"io16YVeDYE0G","colab_type":"text"},"source":["  # Part 1 : Study of the data"]},{"cell_type":"markdown","metadata":{"id":"pWzV-qrfZ0nk","colab_type":"text"},"source":["First, we will study the data. \n","\n","The data is stored in the folder /content/TP3/data.\n","\n","For a patient BraTS19_EXAMPLE, you will have a folder /content/epu_ia_2019/BraTS19_EXAMPLE. Inside this folder you will have nifti files (.nii.gz) for eacch modalities and each z slice. \n","\n","The train, validation and test split are stored in the folder /content/TP3/datasets. For each split, you will have a text files with a list of patient\n","\n","Execute the following code to :\n","*   Load the train, validation and test set\n","*   Print the first 5 patients of the train set\n","*   Print the lenght of the train, validation and test set\n"]},{"cell_type":"code","metadata":{"id":"D1nxaDK_Z1AS","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":109},"outputId":"0f45fe6f-3429-40cd-c37c-4d8fb46d771a","executionInfo":{"status":"ok","timestamp":1581677712983,"user_tz":-60,"elapsed":1034,"user":{"displayName":"Maria Vakalopoulou","photoUrl":"","userId":"15219843109081260770"}}},"source":["path = '/content/TP3/'\n","train_set = np.loadtxt(path + 'datasets/train.txt',dtype=str)\n","validation_set = np.loadtxt(path + 'datasets/val.txt',dtype=str)\n","test_set = np.loadtxt(path + 'datasets/test.txt',dtype=str)\n","\n","# Train_set, validation_set and test_set are list of patients\n","print('Train set : {}'.format(train_set[:5])) # Print the first 5 patients of train_set\n","print('Train set lenght : {}'.format(len(train_set)))\n","print('Validation set lenght : {}'.format(len(validation_set)))\n","print('Test set lenght : {}'.format(len(test_set)))"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Train set : ['BraTS19_CBICA_BHQ_1' 'BraTS19_CBICA_AQV_1' 'BraTS19_CBICA_ATN_1'\n"," 'BraTS19_TCIA01_335_1' 'BraTS19_CBICA_ASY_1']\n","Train set lenght : 251\n","Validation set lenght : 42\n","Test set lenght : 42\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"K8QKnQ_G3Nty","colab_type":"text"},"source":["Execute the following code to :\n","*   Print the first 5 patients in the data folder\n","*   Print the lenght of the data folder\n","*   Select a patient and print the number of images inside the patient folder\n","* Print the number of z slices for one patient\n","* Print the 5 first images of a patient"]},{"cell_type":"code","metadata":{"id":"vYalxEcR3OMz","colab_type":"code","colab":{}},"source":["# The data is store in the folder /content/epu_ia_2019/data/\n","data_path = '/content/TP3/data/'\n","files = os.listdir(data_path) # All the files in the folder /content/epu_ia_2019/data/\n","print('Content of the folder : {}'.format(files[:5]))\n","print('Lenght of the folder : {}'.format(len(files)))\n","\n","# For each patient we have 4 modality and the segmentation in the folder :\n","# t1, t2, flair, t1_ce (gado) and seg. \n","# We also have a file for each slice along the z axis ()\n","patient = 'BraTS19_2013_0_1/'\n","patient_path = os.path.join(data_path, patient)\n","patient_files = os.listdir(patient_path)\n","print('Number of files for each patient : {}'.format(len(patient_files) ))\n","print('Number of slices : {}'.format(len(patient_files) / 5))\n","print('The first five files of the folder : {}'.format(patient_files[:5]))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Quyx7V8lxNqi","colab_type":"text"},"source":["##Exercice 1 : Study of medical images\n","\n","Medical images are stored in specific data type such as dicom or nifti. \n","Theses data types contain not only the images but also medical information. \n","There are many Python librairy to load medical data. We will use SimpleITK. Use help in python in order to find the functions and their syntax\n","\n","\n","You should complete the following code using the functions sitk.GetDirection, sitk.GetOrigin, sitk.GetSpacing, sitk.GetMetaData, sitk.GetMetaDataKeys, sitk.ReadImage, sitk.GetArrayFromImage."]},{"cell_type":"code","metadata":{"id":"0KHGSvJkeDxq","colab_type":"code","colab":{}},"source":["orig_data_path = '/content/TP3/origin_data/'\n","\n","patients = ['BraTS19_CBICA_ANP_1', 'BraTS19_CBICA_AWV_1', 'BraTS19_TCIA01_131_1',\n","            'BraTS19_TCIA10_442_1']\n","\n","modalities = ['_t1', '_t2', '_flair', 't1ce', 'seg']\n","suffix = '.nii.gz'\n","patient = patients[0]\n","modality = modalities[0]\n","patient_folder = os.path.join(orig_data_path,patient) \n","# We use the librairy sitk to open the nifti images\n","image = '''CompleteHere'''(os.path.join(patient_folder, patient + modality + suffix))\n","\n","# Print type of image\n","print('''CompleteHere''')\n","\n","# Print geometrical information\n","print('Image Direction : {}'.format('''CompleteHere'''))\n","print('Image Spacing : {}'.format('''CompleteHere'''))\n","print('Image Origin : {}'.format('''CompleteHere'''))\n","\n","print(image.GetPixel(0, 0, 0))\n","\n","# Get all the information in the meta data\n","keys = '''CompleteHere'''\n","print('Metadata :')\n","for key in keys:\n","  print('{} : {}'.format('''CompleteHere'''))\n","\n","# Convert the sitk image \n","array = '''CompleteHere'''\n","print(type(array)) # Type of the image\n","print(array.shape)\n","print(array[0, 0, 0])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CTfImwXE5UVO","colab_type":"text"},"source":["In order to accelerate the calculation time and have good results quickly, we will work on small images of shape (96, 96). The original images of the dataset have a shape (155, 240, 240) where the 155 correspond to the number of slice on the z axis.\n","\n","The step to pass from the original images to the images we will use are :\n","- Crop the images to a shape of (155, 192, 192)\n","- Downsample the images by interpolation of scale 0.5 (https://scikit-image.org/docs/dev/auto_examples/transform/plot_rescale.html) to a shape of (77, 96, 96)\n","- Save all the z slice independantly in a new array of shape (96, 96)\n","\n","Execute the following code to compare the original image and the preprocessed image.\n","\n","Change the z parameter to plot different slice of the images "]},{"cell_type":"code","metadata":{"id":"k-fAvXoprkWU","colab_type":"code","colab":{}},"source":["orig_data_path = '/content/TP3/origin_data/'\n","patient = patients[0]\n","modality = modalities[0]\n","patient_folder = os.path.join(orig_data_path,patient) \n","# We use the librairy sitk to open the nifti images\n","image = sitk.ReadImage(os.path.join(patient_folder, patient + modality + suffix))\n","orig_array = sitk.GetArrayFromImage(image)\n","print('Orig array shape : {}'.format(orig_array.shape))\n","\n","###\n","data_path = '/content/TP3/data/'\n","patient_folder = os.path.join(data_path,patient)\n","z_slice = 35\n","path = os.path.join(patient_folder, patient + modality + '_z_' + str(z_slice) + suffix)\n","image = sitk.ReadImage(path)\n","processed_array = sitk.GetArrayFromImage(image)\n","print('Processed array shape : {}'.format(processed_array.shape))\n","\n","plt.subplot(1, 2, 1)\n","plt.imshow(orig_array[z_slice*2, :, :], cmap='gray')\n","plt.title('Original array')\n","plt.subplot(1, 2, 2)\n","plt.imshow(processed_array, cmap='gray')\n","plt.title('Processed array')\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t3EVnsmHyP5Q","colab_type":"text"},"source":["[Solution](#scrollTo=GeuCzQ2m7PNy&line=27&uniqifier=1)\n"]},{"cell_type":"markdown","metadata":{"id":"HcVUj8KuXXfN","colab_type":"text"},"source":["# Part 2 : Creation of the neural network"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"xNVPBwaDZnFx"},"source":["The network we will use is called UNet. It is famous network for medical image segmentation. In this part, we will create the network and train our first neural network. You can study the shape of the UNet in the figure 1 of the paper **U-Net: Convolutional Networks for Biomedical Image Segmentation** (https://arxiv.org/pdf/1505.04597.pdf). The UNet has two main features : First the size of the image is downsample by 2 in each block by a layer called **MaxPooling**. Secondly in order to keep information of high resolution, we use **skip-connection** to pass the information from the left part of the network to the right part."]},{"cell_type":"markdown","metadata":{"id":"5qDJ20x-8jPJ","colab_type":"text"},"source":["## Exercice 2 : Create the network\n","\n","- Complete the function DownConvBlock and UpConvBlock. You should use the different layers function from pytorch (Conv2D, BatchNorm2d, MaxPool2d, Upsample)\n","- Try to compare the following code with the figure 1 of the paper. Where are the DownConvBlock, the UpConvBlock ?\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"bQJbRxlfZmAb","colab":{}},"source":["def get_activation(activation_type):\n","    activation_type = activation_type.lower()\n","    if hasattr(nn, activation_type):\n","      return getattr(nn, activation_type)()\n","    else:\n","      return nn.ReLU()\n","\n","def _make_nConv(in_channels, out_channels, nb_Conv, activation='ReLU'):\n","  layers = []\n","  layers.append(ConvBatchNorm(in_channels, out_channels, activation))\n","\n","  for _ in range(nb_Conv-1):\n","      layers.append(ConvBatchNorm(out_channels, out_channels, activation))\n","  return nn.Sequential(*layers)\n","\n","\n","class ConvBatchNorm(nn.Module):\n","  \"\"\"(convolution => [BN] => ReLU)\"\"\"\n","  \n","  def __init__(self, in_channels, out_channels, activation='ReLU'):\n","    super(ConvBatchNorm, self).__init__()\n","    '''CompleteHere'''\n","      \n","  def forward(self, x):\n","    '''CompleteHere'''\n","    return \n","\n","class DownBlock(nn.Module):\n","  \"\"\"Downscaling with maxpool convolution\"\"\"\n","\n","  def __init__(self, in_channels, out_channels, nb_Conv, activation='ReLU'):\n","    super(DownBlock, self).__init__()\n","  '''CompleteHere'''\n","        \n","  def forward(self, x):\n","    '''CompleteHere'''\n","    return \n","\n","class UpBlock(nn.Module):\n","  \"\"\"Upscaling then conv\"\"\"\n","\n","  def __init__(self, in_channels, out_channels, nb_Conv, activation='ReLU'):\n","    super(UpBlock, self).__init__()\n","    '''CompleteHere'''\n","\n","  def forward(self, x, skip_x):\n","    '''CompleteHere'''\n","    return"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"xi_jPXtGZ1-p","colab":{}},"source":["class UNet(nn.Module):\n","  def __init__(self, n_channels, n_classes):\n","    '''\n","    n_channels : number of channels of the input. \n","                    By default 4, because we have 4 modalities\n","    n_labels : number of channels of the ouput.\n","                  By default 4 (3 labels + 1 for the background)\n","    '''\n","    super(UNet, self).__init__()\n","    self.n_channels = n_channels\n","    self.n_classes = n_classes\n","\n","    self.inc = '''CompleteHere'''\n","    self.down1 = '''CompleteHere'''\n","    self.down2 = '''CompleteHere'''\n","    self.down3 = '''CompleteHere'''\n","    self.down4 = '''CompleteHere'''\n","    self.up1 = '''CompleteHere'''\n","    self.up2 = '''CompleteHere'''\n","    self.up3 = '''CompleteHere'''\n","    self.up4 = '''CompleteHere'''\n","    self.outc = '''CompleteHere'''\n","    self.last_activation = get_activation('Softmax')\n","\n","  def forward(self, x):\n","\n","    x1 = '''CompleteHere'''\n","    x2 = '''CompleteHere'''\n","    x3 = '''CompleteHere'''\n","    x4 = '''CompleteHere'''\n","    x5 = '''CompleteHere'''\n","    x = '''CompleteHere'''\n","    x = '''CompleteHere'''\n","    x = '''CompleteHere'''\n","    x = '''CompleteHere'''\n","    logits = self.last_activation(self.outc(x))\n","    return logits"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LNtCpyZv8t8L","colab_type":"text"},"source":["\n","## Exercice 3 : Study the model \n","\n","To study and debug a neural network, you can print the network and print the shape of the x inside the forward block.\n","\n","Execute the following code and answer the following question.\n","- What are the number of convolutionnal layer in our model ?\n","- What is the number of parameters in our model ?\n","- What is the layer with the biggest number of parameters ? Try to find the formula to calculate the number of parameters."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ktk3C0AWapYk","outputId":"98f3f66f-8e23-4c69-fbd8-bf8d5ba9e826","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["model = UNet(n_channels=4, n_classes=4)\n","\n","print(model)\n","\n","# Image of size 96*96 with 4 modality + batch size = 1\n","x = torch.from_numpy(np.random.randn(1, 4, 96, 96)).float()\n","y = model(x)\n","print(y.shape)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["torch.Size([1, 5, 96, 96])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"1nSW0iMhcPDL"},"source":["## Exercice 4 : Dataset\n","\n","This part is used to automatically load the correct images, put them in batch and applying transformation. We will also load the correct train, validation and test sets.\n","\n","Complete the function **get_item** and **load** from the class **SegmentationDataset**"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"1coYIDpScNmD","colab":{}},"source":["modalities = ['_t1', '_t1ce', '_t2', '_flair']\n","end = '.nii.gz'\n","seg_name = '_seg'\n","\n","def load_split(split_folder):\n","    '''\n","        return train, val, test split with loadtxt\n","    '''\n","    train_split = np.loadtxt(os.path.join(\n","        split_folder, 'train.txt'), dtype=str)\n","    val_split = np.loadtxt(os.path.join(split_folder, 'val.txt'), dtype=str)\n","    test_split = np.loadtxt(os.path.join(split_folder, 'test.txt'), dtype=str)\n","\n","    return train_split, val_split, test_split\n","\n","\n","def load_sitk(path):\n","\n","    return sitk.GetArrayFromImage(sitk.ReadImage(path))\n","\n","\n","def find_z_slice(list_patient, threshold, dataframe):\n","\n","    list_IDs = []\n","\n","    for patient in list_patient:\n","\n","        if threshold > 0:\n","          condition = dataframe[patient].values >= threshold\n","          z_slice = np.where(condition)[0]\n","        else:\n","          z_slice = range(155)\n","        list_IDs += list(set([(patient, int(z//2)) for z in z_slice]))\n","\n","    return list_IDs\n","\n","\n","def generate_IDs(train_split, val_split, test_split,\n","                 tumor_percentage, csv_path, image_size=(240, 240)):\n","\n","    tumor_volume_dataframe = pd.read_csv(csv_path)\n","\n","    threshold = int(tumor_percentage * np.prod(image_size) / 100)\n","\n","    train_IDs, val_IDs, test_IDs = [], [], []\n","\n","    train_IDs = find_z_slice(train_split, threshold, tumor_volume_dataframe)\n","    val_IDs = find_z_slice(val_split, threshold, tumor_volume_dataframe)\n","    test_IDs = find_z_slice(test_split, 0, tumor_volume_dataframe)\n","\n","    return train_IDs, val_IDs, test_IDs\n","\n","class SegmentationDataset(torch.utils.data.Dataset):\n","  'Generates data for torch'\n","\n","  def __init__(self, files_list, data_path, transform=None):\n","    'Initialization'\n","    super(SegmentationDataset, self).__init__()\n","    self.files_list = files_list\n","    self.transform = transform\n","    self.data_path = data_path\n","\n","  def __len__(self):\n","    return len(self.files_list)\n","\n","  def __getitem__(self, idx):\n","    'Generate one batch of data'\n","    ''' CompleteHere'''\n","\n","    return (irm, mask, patient)\n","\n","  def load(self, ID):\n","\n","    patient, z_slice = ID\n","    patient_path = os.path.join(self.data_path, patient)\n","\n","    irm = []\n","    for modality in modalities:\n","      path = os.path.join(patient_path,\n","                          '''CompleteHere''')\n","                          \n","      irm.append(load_sitk(path))\n","\n","    irm = np.stack(irm, axis=0)\n","\n","    mask_path = os.path.join(patient_path,\n","                              '''CompleteHere''')\n","    \n","    mask = load_sitk(mask_path)\n","\n","    # Brats dataset has label 4 and not 3\n","    mask[mask == 4] = 3\n","    \n","    # One hot encoding\n","    label = 4\n","    mask = mask.astype(np.int16)\n","    mask = np.rollaxis(np.eye(label, dtype=np.uint8)[mask], -1, 0) \n","      \n","    return irm, mask"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lwuQKFhDAsTd","colab_type":"text"},"source":["**Utils** : group of useful functions to log information, put variable on cuda or on numpy"]},{"cell_type":"code","metadata":{"id":"yLUqBzZ20vJH","colab_type":"code","colab":{}},"source":["def to_var(x, device):\n","    if isinstance(x, np.ndarray):\n","        x = torch.from_numpy(x)\n","    x = x.to(device)\n","    return x\n","\n","def to_numpy(x):\n","    if not (isinstance(x, np.ndarray) or x is None):\n","        if x.is_cuda: \n","            x = x.data.cpu()\n","        x = x.numpy()\n","    return x\n","\n","def save_checkpoint(state, save_path):\n","    '''\n","        Save the current model. \n","        If the model is the best model since beginning of the training\n","        it will be copy\n","    '''\n","\n","    if not os.path.isdir(save_path):\n","        os.makedirs(save_path)\n","\n","    epoch = state['epoch']\n","    val_loss = state['val_loss']\n","    filename = save_path + '/' + \\\n","        'model.{:02d}--{:.3f}.pth.tar'.format(epoch, val_loss)\n","    torch.save(state, filename)\n","\n","\n","def print_summary(epoch, i, nb_batch, loss, batch_time, \n","                  average_loss, average_time, mode):\n","    '''\n","        mode = Train or Test\n","    '''\n","    summary = '[' + str(mode) + '] Epoch: [{0}][{1}/{2}]\\t'.format(\n","        epoch, i, nb_batch)\n","\n","    string = ''\n","    string += ('Dice Loss {:.4f} ').format(loss)\n","    string += ('(Average {:.4f}) \\t').format(average_loss)\n","    string += ('Batch Time {:.4f} ').format(batch_time)\n","    string += ('(Average {:.4f}) \\t').format(average_time)\n","\n","    summary += string\n","\n","    print(summary)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R8BiTvbsAKAh","colab_type":"text"},"source":["**Tensorboard** : This part is used to plot the prediction of the network during the training and study its performance."]},{"cell_type":"code","metadata":{"id":"DvFLBu61x_BX","colab_type":"code","colab":{}},"source":["def plot(irms, masks=None, pred_masks=None):\n","    \n","    kwargs = {'cmap': 'gray'}\n","\n","    fig, ax = plt.subplots(2, 3, gridspec_kw={'wspace': 0.15, 'hspace': 0.2,\n","                                              'top': 0.85, 'bottom': 0.1,\n","                                              'left': 0.05, 'right': 0.95})\n","        \n","    ax[0, 0].imshow(irms[0, :, :], **kwargs)\n","    \n","    if masks is not None:\n","        masks = np.argmax(masks, axis=0)\n","        ax[0, 1].imshow(masks, vmin=0, vmax=3)\n","        \n","    if pred_masks is not None:\n","        pred_masks = np.argmax(pred_masks, axis=0)\n","        ax[0, 2].imshow(pred_masks, vmin=0, vmax=3)\n","\n","    for i in range(3):\n","        ax[1, i].imshow(irms[i+1, :, :], **kwargs)\n","\n","    for i in range(2):\n","        for j in range(3):\n","            ax[i, j].grid(False)\n","            ax[i, j].axis('off')\n","            ax[i, j].set_xticks([])\n","            ax[i, j].set_yticks([])\n","\n","    ax[0, 0].set_title('IRM T1')\n","    ax[1, 0].set_title('IRM Gado')\n","    ax[1, 1].set_title('IRM T2')\n","    ax[1, 2].set_title('IRM Flair')\n","    \n","    ax[0, 1].set_title('Ground Truth Seg')\n","    ax[0, 2].set_title('Predicted Seg')\n","\n","    fig.canvas.draw()\n","    \n","    return fig\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4yH3Zo2l9qTn","colab_type":"text"},"source":["**Loss** : This code is used to code the dice loss which is a loss function dedicated to medical segmentation. "]},{"cell_type":"code","metadata":{"id":"CXuDCj_bJuu_","colab_type":"code","colab":{}},"source":["def dice_loss(input, target):\n","    smooth = 1.\n","    target = target.float()\n","    input = input.float()\n","    input_flat = input.contiguous().view(-1)\n","    target_flat = target.contiguous().view(-1)\n","    intersection = (input_flat * target_flat).sum()\n","    return 1 - ((2. * intersection + smooth) /\n","                (input_flat.pow(2).sum() + target_flat.pow(2).sum() + smooth))\n","\n","def mean_dice_loss(input, target):\n","  \n","  channels = list(range(target.shape[1]))\n","  loss = 0\n","  for channel in channels:\n","    dice = dice_loss(input[:, channel, ...],\n","                     target[:, channel, ...])\n","    loss += dice\n","\n","  return loss / len(channels)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"CiYKEfpIcxHq"},"source":["## Exercice 5 : Main - Train the model \n","\n","To train the model in pytorch, you have different steps :\n","- Choose the optimiser, learning rate and loss function\n","- Create the model\n","- Define the data by using the **Dataset** and **DataLoader** class\n","- Implement the train loop\n","- Launch the training for a number of epochs\n","\n","Complete the following code and launch a training for a small number of epochs (5 or 10 for instance). \n","You should see the loss decreasing. \n","Then open tensorboard to visualise the decrease of the loss and the prediction of the network at the different epochs\n","\n","\n","You need to complete the **train_loop** function and the **MAIN** block"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"d8q7mWgOcwnb","colab":{}},"source":["# Import of the package and choice of the parameters\n","\n","####### Parameters of models #######\n","learning_rate = 1e-4\n","image_size = (96, 96)\n","n_modality = 4\n","n_labels = 4\n","epochs = 10\n","batch_size = 64\n","print_frequency = 5\n","save_frequency = 10\n","save_model = True\n","tumor_percentage = 0.5\n","tensorboard = True\n","main_path = '/content/TP3/'\n","sets_path = os.path.join(main_path, 'datasets/')\n","csv_path = os.path.join(main_path, 'data/tumor_count.csv')\n","data_folder = os.path.join(main_path, 'data/')\n","save_path = '/content/save/'\n","loss_function = 'dice_loss'\n","session_name = 'Test_session' + '_' + time.strftime('%m.%d %Hh%M')\n","model_path = save_path + 'models/' + session_name + '/'\n","tensorboard_folder = save_path + 'tensorboard_logs/'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"TqkvWRgXdPkz","colab":{}},"source":["# Load the split, generate the IDs list and create the DataGenerator\n","train_split, val_split, test_split = load_split(sets_path)\n","(train_IDs, val_IDs,\n"," test_IDs) = generate_IDs(train_split, val_split, test_split,\n","                          tumor_percentage, csv_path)\n","\n","transformation=None\n","train_Dataset = SegmentationDataset(train_IDs, data_path=data_folder,\n","                                    transform=transformation\n","                                    )\n","\n","val_Dataset = SegmentationDataset(val_IDs, data_path=data_folder,\n","                                  transform=transformation\n","                                  )\n","\n","test_Dataset = SegmentationDataset(val_IDs, data_path=data_folder,\n","                                  transform=transformation\n","                                  )\n","        \n","train_loader = torch.utils.data.DataLoader(train_Dataset, \n","                                           batch_size=batch_size, shuffle=True,\n","                                           drop_last=True)\n","\n","val_loader = torch.utils.data.DataLoader(val_Dataset,\n","                                         batch_size=batch_size, drop_last=True) \n","\n","test_loader = torch.utils.data.DataLoader(val_Dataset,\n","                                         batch_size=1, drop_last=False)    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"3AHqde7wdTkM","colab":{}},"source":["# Train the model\n","# Complete the train loop \n","\n","def train_loop(loader, model, criterion, optimizer, writer, epoch):\n","\n","    logging_mode = 'Train' if model.training else 'Val'\n","    \n","    end = time.time()\n","    time_sum, loss_sum = 0, 0\n","    \n","    for i, sample in enumerate(loader, 1):\n","        # Take the variables and put them to GPU\n","        ('''CompleteHere''') = sample\n","        \n","        '''CompleteHere''' = to_var('''CompleteHere'''.float(), device)\n","        '''CompleteHere''' = to_var('''CompleteHere'''.float(), device)\n","\n","        # print(irms.shape) # Batch * Modality * Width * Height\n","    \n","        # compute output\n","        '''CompleteHere'''\n","\n","        # compute loss\n","        '''CompleteHere'''\n","\n","        # compute gradient and do SGD step\n","        if model.training:\n","            '''CompleteHere'''\n","        \n","        # measure elapsed time\n","        batch_time = time.time() - end\n","\n","        time_sum += batch_size*batch_time\n","        loss_sum += batch_size*dice_loss\n","        average_loss = loss_sum / (i * batch_size)\n","        average_time = time_sum / (i * batch_size)\n","\n","        end = time.time()\n","        \n","        if i % print_frequency == 0:\n","            print_summary(epoch + 1, i, len(loader), dice_loss, batch_time,\n","                          average_loss, average_time, logging_mode)\n","        if tensorboard:\n","            step = epoch*len(loader) + i\n","            writer.add_scalar(logging_mode + '_dice', dice_loss.item(),step)\n","\n","    if tensorboard:\n","      n = irms.shape[0]\n","      irms = to_numpy(irms)\n","      masks = to_numpy(masks)\n","      pred_masks = to_numpy(pred_masks)\n","\n","      for batch in range(n):\n","        fig = plot(irms[batch, ...], \n","                   masks[batch, ...], pred_masks[batch, ...])\n","        \n","        writer.add_figure(logging_mode + str(batch), \n","                          fig, epoch)\n","\n","    return dice_loss"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SxyPwfvYw5d5","colab_type":"code","colab":{}},"source":["### MAIN ###\n","\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","model = UNet(n_channels=n_modality, n_classes=n_labels) # Create model\n","model.to(device) # move model to the right device\n","\n","criterion = '''CompleteHere''' # Choose loss function\n","optimizer = '''CompleteHere'''# Choose optimize\n","    \n","if tensorboard:\n","    log_dir = tensorboard_folder + session_name + '/'\n","    if not os.path.isdir(log_dir):\n","        os.makedirs(log_dir)\n","    writer = torch.utils.tensorboard.SummaryWriter(log_dir)\n","else:\n","    writer = None\n","\n","for epoch in range(epochs):  # loop over the dataset multiple times\n","    print('******** Epoch [{}/{}]  ********'.format(epoch+1, epochs+1))\n","    print(session_name)\n","\n","    # train for one epoch\n","    model.train()\n","    print('Training')\n","    train_loop(train_loader, model, criterion, optimizer, writer, epoch)\n","\n","    # evaluate on validation set\n","    print('Validation')\n","    with torch.no_grad():\n","        model.eval()\n","        val_loss = train_loop(val_loader, model, criterion,\n","                              optimizer, writer, epoch)\n","\n","    if save_model and epoch % save_frequency == 0:\n","        save_checkpoint({'epoch': epoch,\n","                        'state_dict': model.state_dict(),\n","                         'val_loss': val_loss,\n","                         'optimizer': optimizer.state_dict()}, model_path)\n","        "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HT2ZKaAFw9Lo","colab_type":"code","colab":{}},"source":["# Load the TensorBoard notebook extension\n","%load_ext tensorboard\n","%tensorboard --logdir '/content/save/tensorboard_logs/'"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Q2kqcqsLqIQm","colab_type":"text"},"source":["# Part 3 : Prediction and Evaluation\n","\n","After training the model we have to perform two steps : the prediction of the segmentation using a model trained and the evaluation of the performance of the network.\n","\n","The evaluation of the network should be done on the validation set (which have not been seen by the network during the training). The test set will only be used when all the parameters of the network are chosen. "]},{"cell_type":"markdown","metadata":{"id":"cnTIU3BrlhsY","colab_type":"text"},"source":["## Exercice 6 : Prediction and returning to original space\n","\n","In this exercice, we will load a network and use the function **predict()** to calculate the predicted segmentation. The predicted segmentation will have a shape (96, 96, 4). We need to transform it back to the 3D shape (155, 240, 240) to perform the evaluation. \n","The steps to calculate the prediction will be : \n","\n","- Apply **predict()** function on a dataloader, with a model. We don't need to calculate the loss and backpropagate them. \n","- Apply **reconstruct_patient()** to find and save in the good order all the slice corresponding to one patient.\n","- Apply **get_mask2original_shape()** to the prediction to go from a shape (78,4,96,96) to (155,240,240)\n","\n","**Questions**\n","- Complete the **predict()** function\n","\n"]},{"cell_type":"code","metadata":{"id":"9vO2Km0fZoND","colab_type":"code","colab":{}},"source":["train_split, val_split, test_split = load_split(sets_path)\n","(train_IDs, val_IDs,\n"," test_IDs) = generate_IDs(train_split, val_split, test_split,\n","                          0, csv_path)\n","\n","transformation=None\n","test_Dataset = SegmentationDataset(test_IDs, data_path=data_folder,\n","                                  transform=transformation\n","                                  )\n","\n","test_loader = torch.utils.data.DataLoader(test_Dataset,\n","                                         batch_size=batch_size, drop_last=False) \n","\n","test_path = '/content/TP3/origin_data/'\n","data_path = '/content/TP3/data/'\n","patients = os.listdir(test_path)\n","patient = patients[0]\n","z_max = 78"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MZCvDnZToenj","colab_type":"code","colab":{}},"source":["def get_mask2original_shape(predict_mask):\n","  '''\n","    input shape is 77*4*96*96\n","  '''\n","  mask = np.zeros(shape=(155,240, 240))\n","  res = skimage.transform.resize(predict_mask, (155, 4, 192, 192))\n","  print('Shape after rescale : {}'.format(res.shape))\n","  res = res > 0.5\n","  res = np.argmax(res, axis=1)\n","  mask[:, 24:-24, 24:-24] = res\n","  mask[mask == 3] = 4\n","  return mask.astype('int')\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hhq4Eat0oJZ1","colab_type":"code","colab":{}},"source":["def predict(loader, model):\n","    preds = {}\n","    for i, sample in tqdm(enumerate(loader, 1)):\n","        # Take variable and put them to GPU\n","        (irms, masks, patients) = '''CompleteHere'''\n","        irms = '''CompleteHere'''\n","        masks = '''CompleteHere'''\n","    \n","        # compute output\n","        pred_masks = '''CompleteHere'''\n","\n","        # Put the predictions in a dictionnary with one key being the \n","        # patient and the z slice\n","        n = pred_masks.shape[0]\n","        for j in range(n):\n","          patient, z_slice = patients[0][j], patients[1][j]\n","          name = patient + '_z_' + str(to_numpy(z_slice))\n","          preds[name] = to_numpy(pred_masks[j])\n","    return preds\n","\n","def reconstruct_patient(preds, patient):\n","  '''\n","    From the dictionnary with prediction find the slice corresponding to \n","    one patient and construct a 3D matrix of shape 77*96*96\n","  '''\n","  X = []\n","  for i in range(z_max):\n","\n","    name = patient + '_z_' + str(i)\n","    array_slice = preds[name]\n","    X.append(array_slice)\n","\n","  X = np.stack(X, axis=0) \n","  return X\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ip7kMGgapCxI","colab_type":"code","colab":{}},"source":["# Do the prediction for the test loader\n","model.eval()\n","with torch.no_grad():\n","  preds = predict(test_loader, model, batch_size=batch_size)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"R1ac8F9PsJgG","colab_type":"code","colab":{}},"source":["# Reconstruct the prediction for one patient and get to its original shape\n","predict_mask = reconstruct_patient(preds, patient)\n","print(predict_mask.shape)\n","predict_mask = get_mask2original_shape(predict_mask)\n","print(predict_mask.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hjT3WF0el3yb","colab_type":"text"},"source":["## Exercice 7 : Visual Comparaison\n","\n","We will do a visual comparaison between the predicted mask and the groundtruth. We will perform the comparaison with **Matplotlib** (python librariry for graph) and a software specialised for medical imaging vizualisation **3D Slicer** (https://www.slicer.org/)\n","\n","**Questions**\n","- Load the groundtruth mask (in folder /content/TP3/origin_data) and using the function **plt.subplot**, **plt.imshow** and **plt.title**, plot the predicted mask and the groundtruth side by side\n","- Change the value of the **z_slice** parameter to explore the segmentation slice by slice\n","- Study the function **numpy2nifti**. What does it do ? Apply it and save the predicted mask as a nifti files. Download the MRI, the groundtruth segmentation and the predicted segmentation and download the software 3D Slicer. Open the nifti files in 3D Slicer and compare the images."]},{"cell_type":"code","metadata":{"id":"TKSDSeAkaBmC","colab_type":"code","colab":{}},"source":["# Compare visual plot of prediction and original mask \n","import matplotlib.pyplot as plt\n","\n","patient_folder = os.path.join(test_path,patient)\n","orig_image = '''CompleteHere'''(os.path.join(patient_folder, \n","                                    patient  + '_seg' + suffix))\n","orig_mask = '''CompleteHere'''(orig_image)\n","\n","z_slice=100\n","\n","plt.subplot(1,2,1)\n","'''CompleteHere'''('''CompleteHere''', vmin=0, vmax=4)\n","'''CompleteHere'''('Original mask (slice {})'.format(z_slice))\n","\n","plt.subplot(1,2,2)\n","'''CompleteHere'''('''CompleteHere''', vmin=0, vmax=4)\n","'''CompleteHere'''('Predicted mask (slice {})'.format(z_slice));"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3A3-sCKcDtp0","colab_type":"code","colab":{}},"source":["def numpy2sitk(predict_mask, orig_img):\n","  '''\n","    Input : predict_mask of type numpy array\n","            orig_img of type SimpleITK image\n","    Output : new_img of type SimpleITK image \n","  '''\n","  new_img = sitk.GetImageFromArray(predict_mask)\n","  new_img.SetDirection(orig_img.GetDirection())\n","  new_img.SetOrigin(orig_img.GetOrigin())\n","  new_img.SetSpacing(orig_img.GetSpacing())\n","  return new_img\n","\n","predict_img = numpy2sitk(predict_mask, orig_image)\n","path = os.path.join(patient_folder, patient + '_predict_seg' + suffix)\n","sitk.WriteImage(predict_img, path) # Save the predictions as nifti images"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"saALPYgDmFzt","colab_type":"text"},"source":["## Exercice 8 : Metrics \n","\n","We will now calculate the evaluation metrics to assess the performance of our model. We will use 3 metrics : the sensitivity (also called true positive rate), the Specificity (also called true negative rate) and the dice score (different of the dice loss used during the training). \n","\n","We will evaluate the metrics on the 5 patients in the folder /content/TP3/origin_data. In the reality, we should evaluate the metrics for all the patient of the validation set (the test set will only be used when we choose the best model and we publish our results).\n","\n","**Questions :**\n","- Complete the **metrics()** function in order to calculate the Dice, Sensitivity and Specificity.\n","\n","- Using, a for loop and all the functions defined in the part 3, calculate the metrics for the 5 patients in the folder /content/TP3/origin_data. You should print the average Dice value for each category (WT, ET, TC)"]},{"cell_type":"code","metadata":{"id":"ebE_L5HE-LXv","colab_type":"code","colab":{}},"source":["import pandas as pd\n","\n","def metrics(mask_, gt_):\n","  '''\n","    Taking to binary array of same shape as input\n","    This function compute the confusion matrix and use it to calculate \n","    Dice metrics, Sensitivity and Specificity\n","    Input : mask_, gt_ numpy array of identic shape (only 1 and 0)\n","    Output : List of 3 scores\n","  '''\n","  lnot = np.logical_not\n","  land = np.logical_and\n","\n","  true_positive = '''CompleteHere'''\n","  false_positive = '''CompleteHere'''\n","  false_negative = '''CompleteHere'''\n","  true_negative = '''CompleteHere'''\n","\n","  M = np.array([[true_negative, false_negative],\n","                [false_positive, true_positive]]).astype(np.float64)\n","  metrics = {}\n","  metrics['Sensitivity'] = '''CompleteHere'''\n","  metrics['Specificity'] = '''CompleteHere'''\n","  metrics['Dice'] = '''CompleteHere'''\n","\n","  return [metrics['Dice'], metrics['Sensitivity'], metrics['Specificity']]\n","\n","\n","def evalAllSample(mask_, gt_):\n","  '''\n","    This functions takes as input two numpy array with labels between\n","    0, 1, 2 and 4 and calculate the metrics as defined in BraTS data challenge\n","    mask_ and gt_ should be array of int\n","  '''\n","  # whole tumor (labels 1,2,4)\n","  mask_wt, gt_wt = (np.array([0, 1, 1, 0, 1])[mask_], \n","                    np.array([0, 1, 1, 0, 1])[gt_])\n","  wt_metrics = metrics(mask_wt, gt_wt)\n","\n","  # tumor core (labels 1,4)\n","  mask_tc, gt_tc = (np.array([0, 1, 0, 0, 1])[mask_], \n","                    np.array([0, 1, 0, 0, 1])[gt_])\n","  tc_metrics = metrics(mask_tc, gt_tc)\n","\n","  # enhancing tumor (label 4)\n","  mask_et, gt_et = (np.array([0, 0, 0, 0, 1])[mask_], \n","                    np.array([0, 0, 0, 0, 1])[gt_])\n","  et_metrics = metrics(mask_et, gt_et)\n","  \n","  return pd.DataFrame({'wt': wt_metrics, 'tc': tc_metrics, 'et': et_metrics},\n","                      index=['Dice', 'Sensitivity', 'Specificity'])\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SLCmi1oC-t8u","colab_type":"code","colab":{}},"source":["wt_dice_list = []\n","et_dice_list = []\n","tc_dice_list = []\n","\n","model.eval()\n","with torch.no_grad():\n","  preds = predict(test_loader, model, batch_size=batch_size)\n","\n","for patient in patients:\n","\n","  patient_folder = os.path.join(test_path,patient)\n","  # load the sitk image and pass it into numpy array\n","  orig_image = '''CompleteHere'''\n","  orig_mask = '''CompleteHere'''\n","  \n","  # Reconstruct the prediction and pass it into the original shape\n","  predict_mask = '''CompleteHere'''\n","  predict_mask = '''CompleteHere'''\n","  \n","  print('*********** {} ***********'.format(patient))\n","  # Calculate scores\n","  scores = '''CompleteHere'''\n","  print(scores)\n","  print()\n","\n","  '''CompleteHere'''.append(scores.loc['Dice', 'wt'])\n","  '''CompleteHere'''.append(scores.loc['Dice', 'et'])\n","  '''CompleteHere'''.append(scores.loc['Dice', 'tc'])\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BlCr9vpxO1-u","colab_type":"code","colab":{}},"source":["print('Whole Tumor Dice : {:.2f}'.format(np.mean(wt_dice_list)))\n","print('Tumor Core Dice : {:.2f}'.format(np.mean(et_dice_list)))\n","print('Enhancing Tumor Dice : {:.2f}'.format(np.mean(tc_dice_list)))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2KV5wjPZ_lo7","colab_type":"text"},"source":["# Part 4 : Data Augmentation\n","\n","In this part we will use data augmentation to increase the performance of the network. The idea with data augmentation is to create new artificial sample so that the network see more data and overfit less.\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"U5zrwq0EFT-S","colab_type":"text"},"source":["## Exercice 8 : Study of the data augmentation\n","\n","Complete each of the following code to see the impact of the data augmentation. Compare the original data and the new artificial images.\n","\n","You need to complete the following class :\n","AxialFlip, RandomCrop and the 3 functions getZoomMatrix, getRotationMatrix, getTranslationMatrix"]},{"cell_type":"code","metadata":{"id":"3opEW1YgEGOw","colab_type":"code","colab":{}},"source":["import scipy\n","import scipy.ndimage\n","import numpy as np\n","\n","class AxialFlip(object):\n","\n","    def __call__(self, sample):\n","\n","        choice_x = np.random.randint(0, 2)\n","        choice_y = np.random.randint(0, 2)\n","        \n","        irm, mask = sample\n","        new_sample = (self.axialflip(irm, choice_x, choice_y),\n","                      self.axialflip(mask, choice_x, choice_y))\n","\n","        return new_sample\n","\n","    def axialflip(self, array, choice_x, choice_y):\n","      '''\n","        Shape of array is Modality * H*W\n","      '''\n","        if choice_x == 1:\n","          '''CompleteHere'''\n","\n","        if choice_y == 1:\n","          '''CompleteHere'''\n","\n","        return np.ascontiguousarray(array)\n","\n","class RandomRotation90(object):\n","    '''\n","        Taken from augment_rot90 from MIC-DKFZ/batchgenerators\n","        https://github.com/MIC-DKFZ/batchgenerators/blob/master/batchgenerators/augmentations/spatial_transformations.py\n","    '''\n","\n","    def __init__(self, num_rot=(1, 2, 3, 4)):\n","\n","        self.num_rot = num_rot\n","        self.axes = (1,2)\n","\n","    def __call__(self, sample):\n","        '''\n","          irm and mask have shape (Modality*Width*Height) and (Label*Width*Height)\n","        '''\n","        num_rot = np.random.choice(self.num_rot)\n","        \n","        def f(img):\n","            return np.ascontiguousarray(np.rot90(img, num_rot, self.axes))\n","        \n","        irm, mask = sample\n","        new_sample = (f(irm), f(mask))\n","\n","        return new_sample\n","\n","class RandomCrop(object):\n","    \"\"\"Crop randomly the image in a sample.\n","\n","    Args:\n","        output_size (tuple or int): Desired output size. If int, cubic crop\n","            is made.\n","    \"\"\"\n","\n","    def __init__(self, output_size, dim=2):\n","        assert isinstance(output_size, (int, tuple, list))\n","        if isinstance(output_size, int):\n","            self.output_size = dim * (output_size,)\n","        else:\n","            assert len(output_size) == dim\n","            self.output_size = output_size  \n","\n","    def __call__(self, sample):\n","        \n","        irm, mask = sample\n","        \n","        _, height, width = irm.shape\n","    \n","        i = '''CompleteHere'''\n","        j = '''CompleteHere'''\n","\n","        def f(img):\n","            return img['''CompleteHere''']\n","\n","        new_sample = ( f(irm), f(mask))\n","\n","        return new_sample\n","\n","def RandomTranslation(max_translation=30, transform_matrix=None, debug=False):\n","    \n","    translation = np.random.randint(-max_translation, max_translation, 2)\n","    \n","    if debug:\n","        return getTranslationMatrix(translation, transform_matrix), (translation)\n","    else:\n","        return getTranslationMatrix(translation, transform_matrix)\n","    \n","def RandomRotation(theta_max=20, transform_matrix=None, debug=False):\n","    \n","    theta = np.random.uniform(-theta_max, theta_max)\n","\n","    if debug:\n","        return getRotationMatrix(theta, transform_matrix), theta\n","    else:\n","        return getRotationMatrix(theta, transform_matrix)\n","\n","def RandomZoom(zoom_max=0.2, transform_matrix=None, debug=False):\n","  \n","  zoom = np.random.uniform(1 - zoom_max, 1 + zoom_max)\n","\n","  if debug:\n","      return getZoomMatrix(zoom, transform_matrix), zoom\n","  else:\n","      return getZoomMatrix(zoom, transform_matrix)\n","\n","def getTranslationMatrix(translation, transform_matrix=None):\n","    '''\n","        2D translation on the axis (0, 1). \n","        Axis 3 is the modality axis\n","        tx: Width shift.\n","        ty: Heigh shift.\n","    \n","    '''\n","    shift_matrix = '''CompleteHere'''\n","\n","    if transform_matrix is None:\n","        transform_matrix = shift_matrix\n","    else:\n","        transform_matrix = np.dot(transform_matrix, shift_matrix)\n","            \n","    return transform_matrix\n","\n","def getZoomMatrix(zoom, transform_matrix=None):\n","    '''\n","        Affine Zoom in 2D\n","        zx: Zoom in x direction.\n","        zy: Zoom in y direction\n","    '''\n","    zoom_matrix = '''CompleteHere'''\n","    if transform_matrix is None:\n","        transform_matrix = zoom_matrix\n","    else:\n","        transform_matrix = np.dot(transform_matrix, zoom_matrix)\n","            \n","    return transform_matrix\n","\n","def getRotationMatrix(theta, transform_matrix=None):\n","    '''\n","        2D rotation on the axis (0, 1). \n","        Axis 3 is the modality axis\n","        theta: Rotation angle in degrees.\n","    '''\n","    theta = np.deg2rad(theta)\n","    rotation_matrix = '''CompleteHere'''\n","    \n","    if transform_matrix is None:\n","        transform_matrix = rotation_matrix\n","    else:\n","        transform_matrix = np.dot(transform_matrix, rotation_matrix)\n","    \n","    return transform_matrix\n","\n","\n","def apply_affine_transform(x, seg=None, transform_matrix=None, crop_shape=None, \n","                           fill_mode='nearest', cval=0., order=3):\n","    \"\"\"Applies an affine transformation specified by the parameters given.\n","    # Arguments\n","        x: 4D numpy array, single image, multimodalities (Modality*H*W)\n","        fill_mode: Points outside the boundaries of the input\n","            are filled according to the given mode\n","            (one of `{'constant', 'nearest', 'reflect', 'wrap'}`).\n","        cval: Value used for points outside the boundaries\n","            of the input if `mode='constant'`.\n","        order: int, order of interpolation\n","    # Returns\n","        The transformed version of the input.\n","    \"\"\"\n","    if scipy is None:\n","        raise ImportError('Image transformations require SciPy. '\n","                          'Install SciPy.')\n","    if transform_matrix is not None:\n","        \n","        channels, h, w = x.shape\n","                \n","        transform_matrix = transform_matrix_offset_center(transform_matrix, \n","                                                          h, w)\n","\n","        res = [ scipy.ndimage.affine_transform(x[channel, ...], transform_matrix,\n","                                              order=order, mode=fill_mode, cval=cval)  for channel in range(channels)]\n","        x = np.stack(res, axis=0)\n","        \n","        if seg is not None:\n","            \n","            labels = seg.shape[0]\n","            res = [scipy.ndimage.affine_transform(seg[label, ...], transform_matrix,\n","                                                                order=order, mode=fill_mode, cval=cval) for label in range(labels)]\n","            \n","            seg = np.stack(res, axis=0)\n","            seg[seg > 0.5] = 1\n","            seg[seg < 0.5] = 0\n","            \n","            return x, seg \n","        \n","    return x\n","\n","def transform_matrix_offset_center(matrix, x, y):\n","    o_x = float(x) / 2 + 0.5\n","    o_y = float(y) / 2 + 0.5\n","    offset_matrix = np.array([[1, 0, o_x], \n","                              [0, 1, o_y],\n","                              [0, 0, 1]])\n","    \n","    reset_matrix = np.array([[1, 0, -o_x], \n","                             [0, 1, -o_y],\n","                             [0, 0, 1]])\n","    \n","    transform_matrix = np.dot(np.dot(offset_matrix, matrix), reset_matrix)\n","    \n","    return transform_matrix\n","\n","class AffineTransform(object):\n","    \n","    def __init__(self, theta=0, max_translation=0, max_zoom=0):\n","\n","        \n","        self.theta = theta\n","        self.max_translation = max_translation\n","        self.max_zoom = max_zoom\n","        \n","    def __call__(self, sample):\n","        \n","        transform_matrix = np.eye(3)\n","\n","        if self.theta > 0:\n","            transform_matrix = RandomRotation(self.theta)\n","\n","        if self.max_translation > 0:\n","            transform_matrix = RandomTranslation(self.max_translation,\n","                                                 transform_matrix)\n","\n","        if self.max_zoom > 0:\n","            transform_matrix = RandomZoom(self.max_zoom,\n","                                          transform_matrix)\n","\n","        new_irm, new_mask = apply_affine_transform(irm, mask, transform_matrix)\n","\n","        return (new_irm, new_mask)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"i4S28vKJ_hXL","colab_type":"code","colab":{}},"source":["k = 3\n","\n","irms, masks, patient = val_loader.__iter__().next()\n","\n","# irms is a list of a numpy array of shape [Batch * W*H*Modality]\n","irm = irms[0,:].numpy()\n","mask = masks[0,:].numpy()\n","\n","fig = plot(irm, mask)\n","fig.suptitle('Original image')\n","fig.savefig(save_path + 'orig.png')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oDNKhDssJoJE","colab_type":"text"},"source":["Axial Flip "]},{"cell_type":"code","metadata":{"id":"AJIcnxHDJnWQ","colab_type":"code","colab":{}},"source":["'''CompleteHere'''\n","for i in range(k):\n","\n","    (new_irm, new_mask) = '''CompleteHere'''((irm, mask))\n","\n","    fig = plot(new_irm, new_mask)\n","    fig.suptitle('Random Axial Flip')\n","    fig.savefig(save_path + 'Axial_Flip{}.png'.format(k))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j_pb5eNdJ-sh","colab_type":"text"},"source":["90° Rotation "]},{"cell_type":"code","metadata":{"id":"fZV_gkMPKBoi","colab_type":"code","colab":{}},"source":["'''CompleteHere'''\n","for i in range(k):\n","\n","    (new_irm, new_mask) = '''CompleteHere'''((irm, mask))\n","\n","    fig = plot(new_irm, new_mask)\n","    fig.suptitle('Random 90° Rotation')\n","    fig.savefig(save_path + 'Random90Rotation{}.png'.format(k))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"72QMAGP7JTcw","colab_type":"code","colab":{}},"source":["'''CompleteHere'''\n","for i in range(k):\n","\n","    (new_irm, new_mask) = '''CompleteHere'''((irm, mask))\n","\n","    fig = plot(new_irm, new_mask)\n","    fig.suptitle('Random crop')\n","    fig.savefig(save_path + 'Random90Rotation{}.png'.format(k))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OJsXnMv-Fgsh","colab_type":"text"},"source":["Random Rotation with +/- 30°"]},{"cell_type":"code","metadata":{"id":"WSjJsOzdFaqc","colab_type":"code","colab":{}},"source":["'''CompleteHere'''\n","for i in range(k):\n","    \n","\n","    (new_irm, new_mask) = '''CompleteHere'''((irm, mask))\n","\n","    fig = plot(new_irm, new_mask)\n","    fig.suptitle('Random rotation')\n","    fig.savefig(save_path + 'Rotation{:.1f}.png'.format(i))\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tGSiqebIFm0d","colab_type":"text"},"source":["Random Translation "]},{"cell_type":"code","metadata":{"id":"JZnTTCMUF-TO","colab_type":"code","colab":{}},"source":["'''CompleteHere'''\n","\n","for i in range(k):\n","    new_irm, new_mask  = '''CompleteHere'''((irm, mask))\n","\n","    fig = plot(new_irm, new_mask)\n","    fig.suptitle('Random translation')\n","    fig.savefig(save_path + 'Translation_{}.png'.format(i))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nWO-77u0F-1j","colab_type":"text"},"source":["Random Zoom"]},{"cell_type":"code","metadata":{"id":"0Q4YHSk8GJcF","colab_type":"code","colab":{}},"source":["'''CompleteHere'''\n","\n","for i in range(k):\n","    (new_irm, new_mask)  = '''CompleteHere'''((irm, mask))\n","\n","    fig = plot(new_irm, new_mask)\n","    fig.suptitle('Random zoom ')\n","    fig.savefig(save_path + 'Zoom_{}.png'.format(k))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6fytm3C4GbZU","colab_type":"text"},"source":["All transformations"]},{"cell_type":"code","metadata":{"id":"PNzPoFz5GbLP","colab_type":"code","colab":{}},"source":["'''CompleteHere'''\n","\n","for i in range(k):\n","    (new_irm, new_mask)  = '''CompleteHere'''((irm, mask))\n","\n","    fig = plot(new_irm, new_mask)\n","    fig.suptitle('Rotation Translation Zoom')\n","    fig.savefig(save_path + 'All_transforms{}.png'.format(i))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zaqqV3VeGngd","colab_type":"text"},"source":["## Exercice 9 : Train with data augmentation\n","\n","Relaunch a new training with data augmentation. The training will take more time than during the previous training."]},{"cell_type":"code","metadata":{"id":"HqiwTM46GnQm","colab_type":"code","colab":{}},"source":["transforms_list = [AffineTransform(theta=15, max_translation=15, max_zoom=0.3),\n","                   AxialFlip(), RandomRotation90(), RandomCrop((64, 64))\n","                   ]\n","\n","transformation = torchvision.transforms.Compose(transforms_list)\n","train_Dataset = SegmentationDataset(train_IDs, data_path=data_folder,\n","                                    transform=transformation\n","                                    )\n","\n","val_Dataset = SegmentationDataset(val_IDs, data_path=data_folder,\n","                                  transform=transformation\n","                                  )\n","\n","train_loader_data_augment = torch.utils.data.DataLoader(train_Dataset, \n","                                           batch_size=batch_size, shuffle=True,\n","                                           drop_last=True)\n","\n","val_loader_data_augment = torch.utils.data.DataLoader(val_Dataset,\n","                                         batch_size=batch_size, drop_last=True) \n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PjSlaLVgQnVL","colab_type":"code","colab":{}},"source":["device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","model = UNet(n_channels=4, n_classes=4) # Create model\n","model.to(device) # move model to the right device\n","\n","criterion = mean_dice_loss # Choose loss function\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) # Choose optimize\n","    \n","if tensorboard:\n","    log_dir = tensorboard_folder + session_name + '/'\n","    if not os.path.isdir(log_dir):\n","        os.makedirs(log_dir)\n","    writer = torch.utils.tensorboard.SummaryWriter(log_dir)\n","else:\n","    writer = None\n","\n","for epoch in range(epochs):  # loop over the dataset multiple times\n","    print('******** Epoch [{}/{}]  ********'.format(epoch+1, epochs+1))\n","    print(session_name)\n","\n","    # train for one epoch\n","    model.train()\n","    print('Training')\n","    train_loop(train_loader_data_augment, model, criterion,\n","               optimizer, writer, epoch)\n","\n","    # evaluate on validation set\n","    print('Validation')\n","    with torch.no_grad():\n","        model.eval()\n","        val_loss = train_loop(val_loader_data_augment, model, criterion,\n","                              optimizer, writer, epoch)\n","\n","    if save_model and epoch % save_frequency == 0:\n","        save_checkpoint({'epoch': epoch,\n","                        'state_dict': model.state_dict(),\n","                         'val_loss': val_loss,\n","                         'optimizer': optimizer.state_dict()}, model_path)\n","        "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uAXgyJdK4UcM","colab_type":"text"},"source":["## Exercice 10 : Comparison of training curves\n","\n","Two models trained for 200 epochs are given in the folder /content/TP3/tensorboard_logs/. The only difference between the two models in that one is using data augmentation and the other not. \n","Open tensorboard and compare the loss, accuracy and prediction for the two models.\n"]},{"cell_type":"code","metadata":{"id":"NKm98J2jIUHE","colab_type":"code","colab":{}},"source":["# Load the TensorBoard notebook extension\n","%load_ext tensorboard\n","%tensorboard --logdir /content/TP3/tensorboard_logs/"],"execution_count":0,"outputs":[]}]}